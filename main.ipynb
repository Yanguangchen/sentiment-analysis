{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e15e75aa",
   "metadata": {},
   "source": [
    "### This workflow includes more advanced steps like calculating weighted sentiment and analyzing rolling correlations, which are suitable for a technical report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521b2e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration and setup complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Yangu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# --- Imports ---\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# --- Download NLTK Data (if needed) ---\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# --- Configuration ---\n",
    "COMPANY_TICKER = \"YYGH\"\n",
    "COMPANY_NAME = \"YY Group Holding Ltd\"\n",
    "INPUT_FILE = \"posts.csv\"  # Switched back to CSV\n",
    "\n",
    "# --- Initialize Tools ---\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "print(\"Configuration and setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4bdc87",
   "metadata": {},
   "source": [
    "## Data Ingestion from Plain Text File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "424fd921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------------------------\n",
      "ERROR: Failed to create DataFrame. It is either empty or missing the 'title' column.\n",
      "Please check your posts.txt file for formatting errors and review any 'SKIPPING' messages above.\n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- Load Posts from the plain text file ---\n",
    "posts_data = []\n",
    "try:\n",
    "    with open(INPUT_FILE, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue # Skip empty lines\n",
    "\n",
    "            parts = line.split('|')\n",
    "            try:\n",
    "                if len(parts) == 3: # Format: YYYY-MM-DD | score | title\n",
    "                    date_str, score_str, title = parts\n",
    "                    score = int(score_str.strip())\n",
    "                elif len(parts) == 2: # Format: YYYY-MM-DD | title\n",
    "                    date_str, title = parts\n",
    "                    score = 1 # Assign a default score of 1\n",
    "                else:\n",
    "                    print(f\"SKIPPING MALFORMED LINE: Line does not have 2 or 3 parts -> {line}\")\n",
    "                    continue\n",
    "\n",
    "                posts_data.append({\n",
    "                    'created_date': pd.to_datetime(date_str.strip()).date(),\n",
    "                    'title': title.strip(),\n",
    "                    'score': score\n",
    "                })\n",
    "            except (ValueError, IndexError) as e:\n",
    "                print(f\"COULD NOT PARSE LINE: {line}. Error: {e}\")\n",
    "\n",
    "    df_posts = pd.DataFrame(posts_data)\n",
    "    \n",
    "    # --- ðŸ’¡ NEW: VALIDATION STEP ---\n",
    "    if df_posts.empty or 'title' not in df_posts.columns:\n",
    "        print(\"\\n-------------------------------------------------------------\")\n",
    "        print(\"ERROR: Failed to create DataFrame. It is either empty or missing the 'title' column.\")\n",
    "        print(\"Please check your posts.txt file for formatting errors and review any 'SKIPPING' messages above.\")\n",
    "        print(\"-------------------------------------------------------------\")\n",
    "    else:\n",
    "        print(f\"Successfully loaded and parsed {len(df_posts)} posts from {INPUT_FILE}.\")\n",
    "        print(\"\\nDataFrame Columns:\", df_posts.columns.tolist())\n",
    "        print(\"DataFrame Head:\")\n",
    "        print(df_posts.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: The file '{INPUT_FILE}' was not found. Please make sure it's in the same directory as your notebook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae2c28c",
   "metadata": {},
   "source": [
    "### 2.0 Methodology\n",
    "\n",
    "#### 2.1 Data Sources\n",
    "-   **Social Media Data:** Posts were analyzed from a pre-compiled dataset contained in a plain text file (`posts.txt`). The dataset consists of post titles, their creation dates, and upvote scores, formatted with a pipe `|` delimiter.\n",
    "-   **Financial Data:** Historical daily stock data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9b29c93",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'title'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# --- Calculate VADER Sentiment ---\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# This applies the sentiment analyzer to each title in the 'title' column.\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m df_posts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_score\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_posts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtitle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m title: sid\u001b[38;5;241m.\u001b[39mpolarity_scores(title)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompound\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# --- Feature Engineering: Weighted Sentiment ---\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# We multiply the sentiment by the post's score to give it more weight.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# We add 1 to the score to prevent multiplying by zero for posts with a score of 0.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m df_posts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_weighted\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_posts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_score\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m (df_posts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Yangu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\Yangu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'title'"
     ]
    }
   ],
   "source": [
    "# --- Calculate VADER Sentiment ---\n",
    "# This applies the sentiment analyzer to each title in the 'title' column.\n",
    "df_posts['sentiment_score'] = df_posts['title'].apply(lambda title: sid.polarity_scores(title)['compound'])\n",
    "\n",
    "# --- Feature Engineering: Weighted Sentiment ---\n",
    "# We multiply the sentiment by the post's score to give it more weight.\n",
    "# We add 1 to the score to prevent multiplying by zero for posts with a score of 0.\n",
    "df_posts['sentiment_weighted'] = df_posts['sentiment_score'] * (df_posts['score'] + 1)\n",
    "\n",
    "print(\"Sentiment analysis and feature engineering complete.\")\n",
    "# Display the results to verify\n",
    "df_posts[['title', 'score', 'sentiment_score', 'sentiment_weighted']].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
